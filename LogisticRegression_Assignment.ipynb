{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMtr6SFTXU4ZHuxKWkX33H6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PratyushPriyamKuanr271776508/pwskills_LogisticRegression/blob/main/LogisticRegression_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. What is Logistic Regression, and how does it differ from Linear Regression?**\n",
        "\n",
        "**Logistic Regression** is a statistical method used for binary classification tasks, where the goal is to predict the probability of an instance belonging to a particular class. It models the relationship between the dependent binary variable and one or more independent variables by estimating probabilities using a logistic function.\n",
        "\n",
        "**Key Differences from Linear Regression:**\n",
        "- **Output**: Linear Regression predicts continuous values, while Logistic Regression predicts probabilities (between 0 and 1) for binary outcomes.\n",
        "- **Equation**: Linear Regression uses a linear equation, while Logistic Regression uses the logistic (sigmoid) function to map predictions to probabilities.\n",
        "- **Purpose**: Linear Regression is used for regression tasks, while Logistic Regression is used for classification tasks.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. What is the mathematical equation of Logistic Regression?**\n",
        "\n",
        "The logistic regression model is represented by the logistic (sigmoid) function:\n",
        "\n",
        "$P(y=1 | X) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\dots + \\beta_n X_n)}}$\n",
        "\n",
        "Where:\n",
        "- \\( P(y=1 | X) \\) is the probability of the dependent variable \\( y \\) being 1 given the input features \\( X \\).\n",
        "- $\\beta_0, \\beta_1, \\dots, \\beta_n $ are the coefficients (parameters) of the model.\n",
        "- $ X_1, X_2, \\dots, X_n $ are the independent variables (features).\n",
        "\n",
        "---\n",
        "\n",
        "### **3. Why do we use the Sigmoid function in Logistic Regression?**\n",
        "\n",
        "The sigmoid function is used because it maps any real-valued number into a value between 0 and 1, which can be interpreted as a probability. This is essential for binary classification tasks. The sigmoid function is defined as:\n",
        "\n",
        "$\\sigma(z) = \\frac{1}{1 + e^{-z}}$\n",
        "\n",
        "Where $z = \\beta_0 + \\beta_1 X_1 + \\dots + \\beta_n X_n$.\n",
        "\n",
        "---\n",
        "\n",
        "### **4. What is the cost function of Logistic Regression?**\n",
        "\n",
        "The cost function for Logistic Regression is the **log loss** (or binary cross-entropy loss):\n",
        "\n",
        "$\n",
        "J(\\beta) = -\\frac{1}{m} \\sum_{i=1}^m \\left[ y^{(i)} \\log(h_\\beta(X^{(i)})) + (1 - y^{(i)}) \\log(1 - h_\\beta(X^{(i)})) \\right]\n",
        "$\n",
        "\n",
        "Where:\n",
        "- $m$ is the number of training examples.\n",
        "- $y^{(i)}$ is the actual label of the \\( i \\)-th example.\n",
        "- $h_\\beta(X^{(i)})$ is the predicted probability for the \\( i \\)-th example.\n",
        "\n",
        "---\n",
        "\n",
        "### **5. What is Regularization in Logistic Regression? Why is it needed?**\n",
        "\n",
        "**Regularization** is a technique used to prevent overfitting by adding a penalty term to the cost function. It discourages the model from fitting noise in the training data by penalizing large coefficients.\n",
        "\n",
        "- **Why it’s needed**: Without regularization, the model might overfit the training data, leading to poor generalization on unseen data.\n",
        "\n",
        "---\n",
        "\n",
        "### **6. Explain the difference between Lasso, Ridge, and Elastic Net regression.**\n",
        "\n",
        "- **Lasso (L1 Regularization)**: Adds a penalty equal to the absolute value of the coefficients. It can shrink some coefficients to zero, effectively performing feature selection.\n",
        "- **Ridge (L2 Regularization)**: Adds a penalty equal to the square of the coefficients. It shrinks coefficients but does not set them to zero.\n",
        "- **Elastic Net**: Combines L1 and L2 regularization. It is useful when there are multiple correlated features.\n",
        "\n",
        "---\n",
        "\n",
        "### **7. When should we use Elastic Net instead of Lasso or Ridge?**\n",
        "\n",
        "Use Elastic Net when:\n",
        "- There are many correlated features (Lasso might select only one, while Elastic Net can select a group).\n",
        "- You want a balance between feature selection (Lasso) and coefficient shrinkage (Ridge).\n",
        "\n",
        "---\n",
        "\n",
        "### **8. What is the impact of the regularization parameter (λ) in Logistic Regression?**\n",
        "\n",
        "The regularization parameter $\\lambda$ controls the strength of regularization:\n",
        "- A large $\\lambda$ increases the penalty, leading to smaller coefficients (stronger regularization).\n",
        "- A small $\\lambda$ reduces the penalty, allowing larger coefficients (weaker regularization).\n",
        "\n",
        "---\n",
        "\n",
        "### **9. What are the key assumptions of Logistic Regression?**\n",
        "\n",
        "1. **Binary Outcome**: The dependent variable is binary.\n",
        "2. **Linearity**: The log-odds of the outcome are linearly related to the independent variables.\n",
        "3. **No Multicollinearity**: Independent variables are not highly correlated.\n",
        "4. **Large Sample Size**: Requires a sufficiently large dataset for reliable estimates.\n",
        "5. **Independent Observations**: Observations should be independent of each other.\n",
        "\n",
        "---\n",
        "\n",
        "### **10. What are some alternatives to Logistic Regression for classification tasks?**\n",
        "\n",
        "- **Decision Trees**\n",
        "- **Random Forests**\n",
        "- **Support Vector Machines (SVM)**\n",
        "- **k-Nearest Neighbors (k-NN)**\n",
        "- **Neural Networks**\n",
        "- **Gradient Boosting Machines (e.g., XGBoost, LightGBM)**\n",
        "\n",
        "---\n",
        "\n",
        "### **11. What are Classification Evaluation Metrics?**\n",
        "\n",
        "Common metrics include:\n",
        "- **Accuracy**: Proportion of correctly classified instances.\n",
        "- **Precision**: Proportion of true positives among predicted positives.\n",
        "- **Recall (Sensitivity)**: Proportion of true positives among actual positives.\n",
        "- **F1-Score**: Harmonic mean of precision and recall.\n",
        "- **ROC-AUC**: Area under the ROC curve, measuring the model’s ability to distinguish between classes.\n",
        "\n",
        "---\n",
        "\n",
        "### **12. How does class imbalance affect Logistic Regression?**\n",
        "\n",
        "Class imbalance can lead to biased predictions, as the model may favor the majority class. Techniques to address this include:\n",
        "- **Resampling**: Oversampling the minority class or undersampling the majority class.\n",
        "- **Class Weights**: Assigning higher weights to the minority class during training.\n",
        "\n",
        "---\n",
        "\n",
        "### **13. What is Hyperparameter Tuning in Logistic Regression?**\n",
        "\n",
        "Hyperparameter tuning involves selecting the best hyperparameters (e.g., regularization strength \\( \\lambda \\), solver type) to optimize model performance. Common methods include:\n",
        "- **Grid Search**\n",
        "- **Random Search**\n",
        "- **Bayesian Optimization**\n",
        "\n",
        "---\n",
        "\n",
        "### **14. What are different solvers in Logistic Regression? Which one should be used?**\n",
        "\n",
        "Common solvers include:\n",
        "- **liblinear**: Suitable for small datasets and binary classification.\n",
        "- **newton-cg**: Efficient for multiclass problems.\n",
        "- **lbfgs**: Works well for medium-sized datasets.\n",
        "- **sag/saga**: Faster for large datasets.\n",
        "\n",
        "The choice depends on the dataset size, type of problem, and regularization.\n",
        "\n",
        "---\n",
        "\n",
        "### **15. How is Logistic Regression extended for multiclass classification?**\n",
        "\n",
        "- **One-vs-Rest (OvR)**: Trains a separate binary classifier for each class.\n",
        "- **Softmax Regression**: Directly generalizes logistic regression to multiple classes using the softmax function.\n",
        "\n",
        "---\n",
        "\n",
        "### **16. What are the advantages and disadvantages of Logistic Regression?**\n",
        "\n",
        "**Advantages**:\n",
        "- Simple and interpretable.\n",
        "- Efficient to train.\n",
        "- Provides probability estimates.\n",
        "\n",
        "**Disadvantages**:\n",
        "- Assumes linearity between features and log-odds.\n",
        "- Struggles with non-linear relationships.\n",
        "- Sensitive to multicollinearity.\n",
        "\n",
        "---\n",
        "\n",
        "### **17. What are some use cases of Logistic Regression?**\n",
        "\n",
        "- **Medical Diagnosis**: Predicting the presence or absence of a disease.\n",
        "- **Credit Scoring**: Predicting loan default.\n",
        "- **Marketing**: Predicting customer churn.\n",
        "- **Fraud Detection**: Identifying fraudulent transactions.\n",
        "\n",
        "---\n",
        "\n",
        "### **18. What is the difference between Softmax Regression and Logistic Regression?**\n",
        "\n",
        "- **Logistic Regression**: Used for binary classification.\n",
        "- **Softmax Regression**: A generalization of logistic regression for multiclass classification, using the softmax function to predict probabilities for each class.\n",
        "\n",
        "---\n",
        "\n",
        "### **19. How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification?**\n",
        "\n",
        "- Use **OvR** when:\n",
        "  - The number of classes is small.\n",
        "  - You want simplicity and interpretability.\n",
        "- Use **Softmax** when:\n",
        "  - The classes are mutually exclusive.\n",
        "  - You want a probabilistic model for multiclass classification.\n",
        "\n",
        "---\n",
        "\n",
        "### **20. How do we interpret coefficients in Logistic Regression?**\n",
        "\n",
        "The coefficients $\\beta_i$ represent the change in the log-odds of the outcome for a one-unit increase in the corresponding feature $X_i$, holding other features constant. To interpret in terms of odds:\n",
        "- Exponentiate the coefficient: $e^{\\beta_i}$ gives the odds ratio.\n",
        "- An odds ratio > 1 indicates an increase in the odds of the outcome, while < 1 indicates a decrease."
      ],
      "metadata": {
        "id": "p2nwO7xnXbBU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Logistic Regression with Train-Test Split and Accuracy**"
      ],
      "metadata": {
        "id": "hDWEZVyBemTm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEfOpS9gXLa7",
        "outputId": "62aa8903-591f-4cd8-9e73-2831b6f07481"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 1.00\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = (data.target == 0).astype(int)  # Binary classification\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Logistic Regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Logistic Regression with L1 Regularization (Lasso)**"
      ],
      "metadata": {
        "id": "Oc9i7pkXewVU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = (data.target == 0).astype(int)  # Binary classification\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Logistic Regression with L1 regularization\n",
        "model = LogisticRegression(penalty='l1', solver='liblinear')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy with L1 Regularization: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4wdZcPHXYBl",
        "outputId": "bdc2d301-b020-40a3-bed5-a111dd9f2f62"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with L1 Regularization: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Logistic Regression with L2 Regularization (Ridge)**"
      ],
      "metadata": {
        "id": "ldACkqUgXZrm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = (data.target == 0).astype(int)  # Binary classification\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Logistic Regression with L2 regularization\n",
        "model = LogisticRegression(penalty='l2')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy with L2 Regularization: {accuracy:.2f}\")\n",
        "print(\"Coefficients:\", model.coef_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylYVBZMHfVLo",
        "outputId": "05939360-f92c-4b48-fa2c-7e9645166404"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with L2 Regularization: 1.00\n",
            "Coefficients: [[-0.43107698  0.84570847 -2.15658006 -0.88940818]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Logistic Regression with Elastic Net Regularization**"
      ],
      "metadata": {
        "id": "KLz2m2nAfcQV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = (data.target == 0).astype(int)  # Binary classification\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Logistic Regression with Elastic Net\n",
        "model = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy with Elastic Net: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QwVakHbfW3I",
        "outputId": "4b074648-87ea-4dce-95eb-e552c71e8b37"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with Elastic Net: 1.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Multiclass Logistic Regression with One-vs-Rest (OvR)**"
      ],
      "metadata": {
        "id": "h5aH6vMbftmA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target  # Multiclass classification\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Logistic Regression with OvR\n",
        "model = LogisticRegression(multi_class='ovr')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy with OvR: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWmUhrVDffG7",
        "outputId": "03e4ee76-456e-49b6-c2f0-a9f67a5826df"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with OvR: 0.96\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Hyperparameter Tuning with GridSearchCV**"
      ],
      "metadata": {
        "id": "xe2BGSVZf1pk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define hyperparameters\n",
        "param_grid = {'C': [0.01, 0.1, 1, 10], 'penalty': ['l1', 'l2']}\n",
        "\n",
        "# Grid Search\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "grid_search = GridSearchCV(model, param_grid, cv=6)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters and accuracy\n",
        "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "y_pred = grid_search.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1-dXpMkfvla",
        "outputId": "d7fbce2c-c81e-49c8-b811-c9217fc9c649"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 10, 'penalty': 'l1'}\n",
            "Model Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. Stratified K-Fold Cross-Validation**"
      ],
      "metadata": {
        "id": "VlXTNmO1gEO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Stratified K-Fold Cross-Validation\n",
        "model = LogisticRegression()\n",
        "cv = StratifiedKFold(n_splits=6, shuffle=True, random_state=42)\n",
        "scores = cross_val_score(model, X, y, cv=cv)\n",
        "\n",
        "# Average accuracy\n",
        "print(f\"Average Accuracy: {scores.mean():.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yWksgPtf3mv",
        "outputId": "b22d4bc4-e4f1-447a-c8b2-f63c7858ea8a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. Load Dataset from CSV and Apply Logistic Regression**"
      ],
      "metadata": {
        "id": "basgYlSegS5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset from CSV\n",
        "df = pd.read_csv('/content/sample_data/california_housing_test.csv')\n",
        "print(df.columns)\n",
        "X = df.drop('median_house_value', axis=1)\n",
        "y = df['median_house_value']\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Logistic Regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0qvpSeZgGp0",
        "outputId": "13544cfa-70ae-4425-ed4e-dbc9feace826"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
            "       'total_bedrooms', 'population', 'households', 'median_income',\n",
            "       'median_house_value'],\n",
            "      dtype='object')\n",
            "Model Accuracy: 0.04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9. RandomizedSearchCV for Hyperparameter Tuning**"
      ],
      "metadata": {
        "id": "akrn_N5ng5Oy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.stats import uniform\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define hyperparameters\n",
        "param_dist = {'C': uniform(0.01, 10), 'penalty': ['l2']}\n",
        "\n",
        "# Randomized Search\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "random_search = RandomizedSearchCV(model, param_dist, n_iter=10, cv=5)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters and accuracy\n",
        "print(f\"Best Parameters: {random_search.best_params_}\")\n",
        "y_pred = random_search.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCifwCmzgey9",
        "outputId": "f87b8bde-8f7d-43ea-cbc3-15ddd2a293e9"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': np.float64(6.902249233457046), 'penalty': 'l2'}\n",
            "Model Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10. One-vs-One (OvO) Multiclass Logistic Regression**"
      ],
      "metadata": {
        "id": "fZHZCJXChM2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Logistic Regression with OvO\n",
        "model = LogisticRegression(multi_class='multinomial', solver='newton-cg')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy with OvO: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGpCvMmShJaX",
        "outputId": "d1c92131-09b1-4857-f882-f0b036655cce"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with OvO: 1.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**12. Precision, Recall, and F1-Score Evaluation**"
      ],
      "metadata": {
        "id": "MWOPL-32hRDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = (data.target == 0).astype(int)  # Binary classification\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Logistic Regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1-Score: {f1:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7nz9mKihQLN",
        "outputId": "e0df4480-407e-4408-9540-69df98750d27"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 1.00, Recall: 1.00, F1-Score: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**11. Confusion Matrix for Binary Classification**"
      ],
      "metadata": {
        "id": "8xj7a7hikj_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = (data.target == 0).astype(int)  # Binary classification\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Logistic Regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and plot confusion matrix\n",
        "y_pred = model.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "ZSF9M4_DhadG",
        "outputId": "17214ad0-db75-4cc9-a6f8-e5e1e2ce3581"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAHHCAYAAABEJtrOAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAN3lJREFUeJzt3Xd8VGXa//HvJCGTBFIIJSESQpMmTVFZFmk/kaIiiK6AuAYEXF2wgKCiUi3ZB1dAFEVXJeDCig0UdFHK0gR1QSMWiCSgoHQQQgJpM+f3R8ysQ0BmMjOZcj7v1+u8HueeU66TJ8uV677vc26LYRiGAABAUArzdwAAAKDySOQAAAQxEjkAAEGMRA4AQBAjkQMAEMRI5AAABDESOQAAQYxEDgBAECORAwAQxEjkwFl27dqlXr16KT4+XhaLRcuWLfPq+X/44QdZLBZlZmZ69bzBrHv37urevbu/wwCCEokcASk3N1d/+ctf1LhxY0VFRSkuLk6dO3fWs88+qzNnzvj02unp6fr666/15JNP6vXXX9fll1/u0+tVpWHDhslisSguLu6cP8ddu3bJYrHIYrHo73//u9vn379/v6ZOnaqsrCwvRAvAFRH+DgA42wcffKA//elPslqtuv3229W6dWsVFxdr06ZNmjBhgr799lu9/PLLPrn2mTNntGXLFj366KMaM2aMT66RlpamM2fOqFq1aj45/4VERETo9OnTWr58uW655Ran7xYtWqSoqCgVFhZW6tz79+/XtGnT1LBhQ7Vv397l4z7++ONKXQ8AiRwBZs+ePRo8eLDS0tK0du1a1atXz/Hd6NGjlZOTow8++MBn1z9y5IgkKSEhwWfXsFgsioqK8tn5L8Rqtapz587617/+VSGRL168WNddd53eeeedKonl9OnTiomJUWRkZJVcDwhFdK0joMyYMUP5+fl69dVXnZJ4uaZNm+q+++5zfC4tLdXjjz+uJk2ayGq1qmHDhnrkkUdUVFTkdFzDhg11/fXXa9OmTbryyisVFRWlxo0ba+HChY59pk6dqrS0NEnShAkTZLFY1LBhQ0llXdLl//1bU6dOlcVicWpbtWqVrrrqKiUkJKhGjRpq3ry5HnnkEcf35xsjX7t2rbp06aLq1asrISFB/fv3144dO855vZycHA0bNkwJCQmKj4/X8OHDdfr06fP/YM9y66236t///rdOnDjhaPvvf/+rXbt26dZbb62w//HjxzV+/Hi1adNGNWrUUFxcnPr27auvvvrKsc+6det0xRVXSJKGDx/u6KIvv8/u3burdevW2rZtm7p27aqYmBjHz+XsMfL09HRFRUVVuP/evXurZs2a2r9/v8v3CoQ6EjkCyvLly9W4cWP98Y9/dGn/kSNHavLkybrssss0a9YsdevWTRkZGRo8eHCFfXNycnTzzTfrmmuu0TPPPKOaNWtq2LBh+vbbbyVJAwcO1KxZsyRJQ4YM0euvv67Zs2e7Ff+3336r66+/XkVFRZo+fbqeeeYZ3XDDDfrkk09+97jVq1erd+/eOnz4sKZOnapx48Zp8+bN6ty5s3744YcK+99yyy06deqUMjIydMsttygzM1PTpk1zOc6BAwfKYrHo3XffdbQtXrxYLVq00GWXXVZh/927d2vZsmW6/vrrNXPmTE2YMEFff/21unXr5kiqLVu21PTp0yVJd955p15//XW9/vrr6tq1q+M8x44dU9++fdW+fXvNnj1bPXr0OGd8zz77rOrUqaP09HTZbDZJ0ksvvaSPP/5Yzz33nFJSUly+VyDkGUCAOHnypCHJ6N+/v0v7Z2VlGZKMkSNHOrWPHz/ekGSsXbvW0ZaWlmZIMjZs2OBoO3z4sGG1Wo0HHnjA0bZnzx5DkvH00087nTM9Pd1IS0urEMOUKVOM3/7PaNasWYYk48iRI+eNu/wa8+fPd7S1b9/eqFu3rnHs2DFH21dffWWEhYUZt99+e4Xr3XHHHU7nvPHGG41atWqd95q/vY/q1asbhmEYN998s3H11VcbhmEYNpvNSE5ONqZNm3bOn0FhYaFhs9kq3IfVajWmT5/uaPvvf/9b4d7KdevWzZBkzJs375zfdevWzanto48+MiQZTzzxhLF7926jRo0axoABAy54j4DZUJEjYOTl5UmSYmNjXdr/ww8/lCSNGzfOqf2BBx6QpApj6a1atVKXLl0cn+vUqaPmzZtr9+7dlY75bOVj6++9957sdrtLxxw4cEBZWVkaNmyYEhMTHe1t27bVNddc47jP37rrrrucPnfp0kXHjh1z/Axdceutt2rdunU6ePCg1q5dq4MHD56zW10qG1cPCyv758Jms+nYsWOOYYMvvvjC5WtarVYNHz7cpX179eqlv/zlL5o+fboGDhyoqKgovfTSSy5fCzALEjkCRlxcnCTp1KlTLu3/448/KiwsTE2bNnVqT05OVkJCgn788Uen9gYNGlQ4R82aNfXLL79UMuKKBg0apM6dO2vkyJFKSkrS4MGD9eabb/5uUi+Ps3nz5hW+a9mypY4ePaqCggKn9rPvpWbNmpLk1r1ce+21io2N1ZIlS7Ro0SJdccUVFX6W5ex2u2bNmqWLL75YVqtVtWvXVp06dbR9+3adPHnS5WtedNFFbk1s+/vf/67ExERlZWVpzpw5qlu3rsvHAmZBIkfAiIuLU0pKir755hu3jjt7stn5hIeHn7PdMIxKX6N8/LZcdHS0NmzYoNWrV+vPf/6ztm/frkGDBumaa66psK8nPLmXclarVQMHDtSCBQu0dOnS81bjkvTUU09p3Lhx6tq1q/75z3/qo48+0qpVq3TJJZe43PMglf183PHll1/q8OHDkqSvv/7arWMBsyCRI6Bcf/31ys3N1ZYtWy64b1pamux2u3bt2uXUfujQIZ04ccIxA90batas6TTDu9zZVb8khYWF6eqrr9bMmTP13Xff6cknn9TatWv1n//855znLo8zOzu7wnc7d+5U7dq1Vb16dc9u4DxuvfVWffnllzp16tQ5JwiWe/vtt9WjRw+9+uqrGjx4sHr16qWePXtW+Jm4+keVKwoKCjR8+HC1atVKd955p2bMmKH//ve/Xjs/ECpI5AgoDz74oKpXr66RI0fq0KFDFb7Pzc3Vs88+K6msa1hShZnlM2fOlCRdd911XourSZMmOnnypLZv3+5oO3DggJYuXeq03/HjxyscW/5ilLMfiStXr149tW/fXgsWLHBKjN98840+/vhjx336Qo8ePfT444/r+eefV3Jy8nn3Cw8Pr1Dtv/XWW/r555+d2sr/4DjXHz3ueuihh7R3714tWLBAM2fOVMOGDZWenn7enyNgVrwQBgGlSZMmWrx4sQYNGqSWLVs6vdlt8+bNeuuttzRs2DBJUrt27ZSenq6XX35ZJ06cULdu3fT5559rwYIFGjBgwHkfbaqMwYMH66GHHtKNN96oe++9V6dPn9aLL76oZs2aOU32mj59ujZs2KDrrrtOaWlpOnz4sF544QXVr19fV1111XnP//TTT6tv377q1KmTRowYoTNnzui5555TfHy8pk6d6rX7OFtYWJgee+yxC+53/fXXa/r06Ro+fLj++Mc/6uuvv9aiRYvUuHFjp/2aNGmihIQEzZs3T7Gxsapevbo6duyoRo0auRXX2rVr9cILL2jKlCmOx+Hmz5+v7t27a9KkSZoxY4Zb5wNCmp9nzQPn9P333xujRo0yGjZsaERGRhqxsbFG586djeeee84oLCx07FdSUmJMmzbNaNSokVGtWjUjNTXVmDhxotM+hlH2+Nl1111X4TpnP/Z0vsfPDMMwPv74Y6N169ZGZGSk0bx5c+Of//xnhcfP1qxZY/Tv399ISUkxIiMjjZSUFGPIkCHG999/X+EaZz+itXr1aqNz585GdHS0ERcXZ/Tr18/47rvvnPYpv97Zj7fNnz/fkGTs2bPnvD9Tw3B+/Ox8zvf42QMPPGDUq1fPiI6ONjp37mxs2bLlnI+Nvffee0arVq2MiIgIp/vs1q2bcckll5zzmr89T15enpGWlmZcdtllRklJidN+Y8eONcLCwowtW7b87j0AZmIxDDdmxwAAgIDCGDkAAEGMRA4AQBAjkQMAEMRI5AAABDESOQAAQYxEDgBAEAvqF8LY7Xbt379fsbGxXn01JACgahiGoVOnTiklJcWxwp4vFBYWqri42OPzREZGKioqygsReU9QJ/L9+/crNTXV32EAADy0b98+1a9f3yfnLiwsVKO0Gjp42POFi5KTk7Vnz56ASuZBncjL163+8YuGiqvBKAFC043N2vg7BMBnSlWiTfrQ8e+5LxQXF+vgYZt+3NZQcbGVzxV5p+xK6/CDiouLSeTeUt6dHlcjzKP/5wCBLMJSzd8hAL7z67tFq2J4tEasRTViK38duwJzCDeoEzkAAK6yGXbZPHgpuc2wey8YLyKRAwBMwS5DdlU+k3tyrC/RHw0AQBCjIgcAmIJddnnSOe7Z0b5DIgcAmILNMGTzYOVuT471JbrWAQAIYlTkAABTYLIbAABBzC5DNg82dxN5RkaGrrjiCsXGxqpu3boaMGCAsrOznfbp3r27LBaL03bXXXe5dR0SOQAAPrB+/XqNHj1an376qVatWqWSkhL16tVLBQUFTvuNGjVKBw4ccGwzZsxw6zp0rQMATKGqu9ZXrlzp9DkzM1N169bVtm3b1LVrV0d7TEyMkpOTKx0XFTkAwBTKZ617sklSXl6e01ZUVOTS9U+ePClJSkxMdGpftGiRateurdatW2vixIk6ffq0W/dFRQ4AgBvOXnVzypQpmjp16u8eY7fbdf/996tz585q3bq1o/3WW29VWlqaUlJStH37dj300EPKzs7Wu+++63I8JHIAgCnYf908OV4qW3I1Li7O0W61Wi947OjRo/XNN99o06ZNTu133nmn47/btGmjevXq6eqrr1Zubq6aNGniUlwkcgCAKZTPPvfkeEmKi4tzSuQXMmbMGK1YsUIbNmy44JrrHTt2lCTl5OSQyAEA+C2bIQ9XP3Nvf8MwdM8992jp0qVat26dGjVqdMFjsrKyJEn16tVz+TokcgAAfGD06NFavHix3nvvPcXGxurgwYOSpPj4eEVHRys3N1eLFy/Wtddeq1q1amn79u0aO3asunbtqrZt27p8HRI5AMAUvDVG7qoXX3xRUtlLX35r/vz5GjZsmCIjI7V69WrNnj1bBQUFSk1N1U033aTHHnvMreuQyAEApmCXRTZZPDreHcYFFllJTU3V+vXrKx1POZ4jBwAgiFGRAwBMwW6UbZ4cH4hI5AAAU7B52LXuybG+RNc6AABBjIocAGAKoVqRk8gBAKZgNyyyGx7MWvfgWF+iax0AgCBGRQ4AMAW61gEACGI2hcnmQUe0zYuxeBOJHABgCoaHY+QGY+QAAMDbqMgBAKbAGDkAAEHMZoTJZngwRh6gr2ilax0AgCBGRQ4AMAW7LLJ7UL/aFZglOYkcAGAKoTpGTtc6AABBjIocAGAKnk92o2sdAAC/KRsj92DRFLrWAQCAt1GRAwBMwe7hu9aZtQ4AgB8xRg4AQBCzKywknyNnjBwAgCBGRQ4AMAWbYZHNg6VIPTnWl0jkAABTsHk42c1G1zoAAPA2KnIAgCnYjTDZPZi1bmfWOgAA/kPXOgAACDhU5AAAU7DLs5nndu+F4lUkcgCAKXj+QpjA7MQOzKgAAIBLqMgBAKbg+bvWA7P2JZEDAEwhVNcjJ5EDAEwhVCvywIwKAAC4hIocAGAKnr8QJjBrXxI5AMAU7IZFdk+eIw/Q1c8C888LAADgEipyAIAp2D3sWg/UF8KQyAEApuD56meBmcgDMyoAAOASKnIAgCnYZJHNg5e6eHKsL5HIAQCmQNc6AAAIOFTkAABTsMmz7nGb90LxKhI5AMAUQrVrnUQOADAFFk0BAAABh4ocAGAKhofrkRs8fgYAgP/QtQ4AAAIOFTkAwBRCdRlTEjkAwBRsHq5+5smxvhSYUQEAAJdQkQMATIGudQAAgphdYbJ70BHtybG+FJhRAQAAl1CRAwBMwWZYZPOge9yTY32JihwAYArlY+SebO7IyMjQFVdcodjYWNWtW1cDBgxQdna20z6FhYUaPXq0atWqpRo1auimm27SoUOH3LoOiRwAYArGr6ufVXYz3Hyz2/r16zV69Gh9+umnWrVqlUpKStSrVy8VFBQ49hk7dqyWL1+ut956S+vXr9f+/fs1cOBAt65D1zoAAD6wcuVKp8+ZmZmqW7eutm3bpq5du+rkyZN69dVXtXjxYv2///f/JEnz589Xy5Yt9emnn+oPf/iDS9ehIgcAmIJNFo83ScrLy3PaioqKXLr+yZMnJUmJiYmSpG3btqmkpEQ9e/Z07NOiRQs1aNBAW7Zscfm+SOQAAFOwG56Ok5edJzU1VfHx8Y4tIyPjwte223X//ferc+fOat26tSTp4MGDioyMVEJCgtO+SUlJOnjwoMv3Rdc6AABu2Ldvn+Li4hyfrVbrBY8ZPXq0vvnmG23atMnr8ZDIUcEbz9XVJx8maF+OVZFRdrW6/LRGPLpfqU2du4++2xqjzP+rp51fxCg8XGp8yRk9tThX1mjDT5EDnuk37KhuvvuwEuuUavd30XrhsYuUnRXj77DgJeWT1jw5XpLi4uKcEvmFjBkzRitWrNCGDRtUv359R3tycrKKi4t14sQJp6r80KFDSk5Odvn8AdG1PnfuXDVs2FBRUVHq2LGjPv/8c3+HZGrbt9RQv2FHNXvFLmW8kStbqfTIkCYqPP2/X5fvtsbo0aFN1KHrKc35cJfmfPi9bhh+VJaA+I0C3Nfthl9055T9WjQzWaN7N9Pu76L05OLdiq9V4u/Q4CV2WTze3GEYhsaMGaOlS5dq7dq1atSokdP3HTp0ULVq1bRmzRpHW3Z2tvbu3atOnTq5fB2/V+RLlizRuHHjNG/ePHXs2FGzZ89W7969lZ2drbp16/o7PFN6avFup88PzN6rQW3aaNf2aLX5Q9ljEy9NvUgDRhzRoHsOO/Y7u2IHgsnAO49q5eJEfbykbCLSnIfq68qr89R7yHG9+XySn6NDMBo9erQWL16s9957T7GxsY5x7/j4eEVHRys+Pl4jRozQuHHjlJiYqLi4ON1zzz3q1KmTyzPWpQCoyGfOnKlRo0Zp+PDhatWqlebNm6eYmBi99tpr/g4NvyrIC5ckxSbYJEknjkZo5xfVlVCrVPf3u1iD2l6i8QOb6pvPqvszTKDSIqrZdXHb0/piY6yjzTAs+nJjrFp1OO3HyOBN5W9282Rzx4svvqiTJ0+qe/fuqlevnmNbsmSJY59Zs2bp+uuv10033aSuXbsqOTlZ7777rlvX8WtFXlxcrG3btmnixImOtrCwMPXs2dOtqffwHbtdmjflIl1yRb4atiiUJB34MVKS9PrMZI2atF9NLjmj1W/X1MODmuiltTt1UeNif4YMuC0u0abwCOnEEed/En85GkFPUwjx1hi5qwzjwvOFoqKiNHfuXM2dO7eyYfk3kR89elQ2m01JSc7dVklJSdq5c2eF/YuKipye18vLy/N5jGb3/CP19ePOaD2zbJejzW4v+7/X3nZMvQcflyQ1bXNGWZti9dEbtXTHIwf8ESoAmJLfu9bdkZGR4fTsXmpqqr9DCmnPP3KRPlsVpxlv56hOyv8m/NRKKpUkpTUrdNo/tWmhDv9crUpjBLwh73i4bKVSQp1Sp/aatUv1yxG/TyWCl9jl4bvW3ZzsVlX8mshr166t8PDwCi+IP9/U+4kTJ+rkyZOObd++fVUVqqkYRlkS37wyXjPeylFyA+eu8qTUYtVKLtZPuc7PTv6826q69Znhi+BTWhKmXdtjdOlVpxxtFouh9lfl67ttPH4WKgwPZ6wbJPKKIiMj1aFDB6ep93a7XWvWrDnn1Hur1ep4fs/d5/jguucfqa+17ybq4bk/KrqGXccPR+j44QgVnSn7JbZYpJvvPqJlr9bRxhXx+nlPpBbMSNa+3Cj1GXLMz9EDlfPuy7XV99bj6vmn40ptWqh7/vaTomLs+viNRH+HBi+p6tXPqorf+4zGjRun9PR0XX755bryyis1e/ZsFRQUaPjw4f4OzbRWLKgtSZpw08VO7Q/M2qteg8rGxAeOOqKSQovmTblIp06Eq3GrQmX8K1cpDZnohuC0/v2aiq9l0+0TDqpmnVLt/jZajw5tpBNHGS5CYPN7Ih80aJCOHDmiyZMn6+DBg2rfvr1WrlxZYQIcqs5H+7Nc2m/QPYedniMHgt3782vr/fm1/R0GfKSqZ61XFb8ncqns9XVjxozxdxgAgBDmafd4oHatB+afFwAAwCUBUZEDAOBrlXlf+tnHByISOQDAFOhaBwAAAYeKHABgCqFakZPIAQCmEKqJnK51AACCGBU5AMAUQrUiJ5EDAEzBkGePkF14dXH/IJEDAEwhVCtyxsgBAAhiVOQAAFMI1YqcRA4AMIVQTeR0rQMAEMSoyAEAphCqFTmJHABgCoZhkeFBMvbkWF+iax0AgCBGRQ4AMAXWIwcAIIiF6hg5XesAAAQxKnIAgCmE6mQ3EjkAwBRCtWudRA4AMIVQrcgZIwcAIIhRkQMATMHwsGs9UCtyEjkAwBQMSYbh2fGBiK51AACCGBU5AMAU7LLIwpvdAAAITsxaBwAAAYeKHABgCnbDIgsvhAEAIDgZhoez1gN02jpd6wAABDEqcgCAKYTqZDcSOQDAFEjkAAAEsVCd7MYYOQAAQYyKHABgCqE6a51EDgAwhbJE7skYuReD8SK61gEACGJU5AAAU2DWOgAAQcyQZ2uKB2jPOl3rAAAEMypyAIAp0LUOAEAwC9G+dRI5AMAcPKzIFaAVOWPkAAAEMSpyAIAp8GY3AACCWKhOdqNrHQCAIEZFDgAwB8Pi2YS1AK3ISeQAAFMI1TFyutYBAAhiJHIAgDkYXtjcsGHDBvXr108pKSmyWCxatmyZ0/fDhg2TxWJx2vr06eP2bbnUtf7++++7fMIbbrjB7SAAAPC1qp61XlBQoHbt2umOO+7QwIEDz7lPnz59NH/+fMdnq9XqdlwuJfIBAwa4dDKLxSKbzeZ2EAAAhJq+ffuqb9++v7uP1WpVcnKyR9dxqWvdbre7tJHEAQABzQvd6nl5eU5bUVFRpcNZt26d6tatq+bNm+vuu+/WsWPH3D6HR2PkhYWFnhwOAECVKe9a92STpNTUVMXHxzu2jIyMSsXTp08fLVy4UGvWrNH//d//af369erbt6/bRbHbj5/ZbDY99dRTmjdvng4dOqTvv/9ejRs31qRJk9SwYUONGDHC3VMCAOB7Xlr9bN++fYqLi3M0V2ZcW5IGDx7s+O82bdqobdu2atKkidatW6err77a5fO4XZE/+eSTyszM1IwZMxQZGelob926tV555RV3TwcAQFCJi4tz2iqbyM/WuHFj1a5dWzk5OW4d53YiX7hwoV5++WUNHTpU4eHhjvZ27dpp586d7p4OAIAqYvHC5js//fSTjh07pnr16rl1nNtd6z///LOaNm1aod1ut6ukpMTd0wEAUDW81LXuqvz8fKfqes+ePcrKylJiYqISExM1bdo03XTTTUpOTlZubq4efPBBNW3aVL1793brOm5X5K1atdLGjRsrtL/99tu69NJL3T0dAAAhaevWrbr00ksduXHcuHG69NJLNXnyZIWHh2v79u264YYb1KxZM40YMUIdOnTQxo0b3e6qd7sinzx5stLT0/Xzzz/Lbrfr3XffVXZ2thYuXKgVK1a4ezoAAKpGFVfk3bt3l/E7L2j/6KOPPAjmf9yuyPv376/ly5dr9erVql69uiZPnqwdO3Zo+fLluuaaa7wSFAAAXle++pknWwCq1OpnXbp00apVq7wdCwAAcFOllzHdunWrduzYIals3LxDhw5eCwoAAG8L1WVM3U7kP/30k4YMGaJPPvlECQkJkqQTJ07oj3/8o9544w3Vr1/f2zECAOC5Kh4jrypuj5GPHDlSJSUl2rFjh44fP67jx49rx44dstvtGjlypC9iBAAA5+F2Rb5+/Xpt3rxZzZs3d7Q1b95czz33nLp06eLV4AAA8BpPJ6yFymS31NTUc774xWazKSUlxStBAQDgbRajbPPk+EDkdtf6008/rXvuuUdbt251tG3dulX33Xef/v73v3s1OAAAvMaTJUw9HV/3IZcq8po1a8pi+V+XQkFBgTp27KiIiLLDS0tLFRERoTvuuEMDBgzwSaAAAKAilxL57NmzfRwGAAA+ZuYx8vT0dF/HAQCAb4Xo42eVfiGMJBUWFqq4uNip7beLrQMAAN9ye7JbQUGBxowZo7p166p69eqqWbOm0wYAQEAK0clubifyBx98UGvXrtWLL74oq9WqV155RdOmTVNKSooWLlzoixgBAPBciCZyt7vWly9froULF6p79+4aPny4unTpoqZNmyotLU2LFi3S0KFDfREnAAA4B7cr8uPHj6tx48aSysbDjx8/Lkm66qqrtGHDBu9GBwCAt4ToMqZuJ/LGjRtrz549kqQWLVrozTfflFRWqZcvogIAQKApf7ObJ1sgcjuRDx8+XF999ZUk6eGHH9bcuXMVFRWlsWPHasKECV4PEAAAnJ/bY+Rjx451/HfPnj21c+dObdu2TU2bNlXbtm29GhwAAF7Dc+TnlpaWprS0NG/EAgAA3ORSIp8zZ47LJ7z33nsrHQwAAL5ikYern3ktEu9yKZHPmjXLpZNZLBYSOQAAVcilRF4+Sz1Q3disjSIs1fwdBuAT8Ztq+TsEwGdKCoqlXlV0MTMvmgIAQNAL0clubj9+BgAAAgcVOQDAHEK0IieRAwBMwdO3s4XMm90AAEDgqFQi37hxo2677TZ16tRJP//8syTp9ddf16ZNm7waHAAAXhOiy5i6ncjfeecd9e7dW9HR0fryyy9VVFQkSTp58qSeeuoprwcIAIBXkMjLPPHEE5o3b57+8Y9/qFq1/z273blzZ33xxRdeDQ4AAPw+tye7ZWdnq2vXrhXa4+PjdeLECW/EBACA1zHZ7VfJycnKycmp0L5p0yY1btzYK0EBAOB15W9282QLQG4n8lGjRum+++7TZ599JovFov3792vRokUaP3687r77bl/ECACA50J0jNztrvWHH35YdrtdV199tU6fPq2uXbvKarVq/Pjxuueee3wRIwAAOA+3E7nFYtGjjz6qCRMmKCcnR/n5+WrVqpVq1Kjhi/gAAPCKUB0jr/Sb3SIjI9WqVStvxgIAgO/witYyPXr0kMVy/gH/tWvXehQQAABwnduJvH379k6fS0pKlJWVpW+++Ubp6eneigsAAO/ysGs9ZCryWbNmnbN96tSpys/P9zggAAB8IkS71r22aMptt92m1157zVunAwAALvDaMqZbtmxRVFSUt04HAIB3hWhF7nYiHzhwoNNnwzB04MABbd26VZMmTfJaYAAAeBOPn/0qPj7e6XNYWJiaN2+u6dOnq1evXl4LDAAAXJhbidxms2n48OFq06aNatas6auYAACAi9ya7BYeHq5evXqxyhkAIPiE6LvW3Z613rp1a+3evdsXsQAA4DPlY+SebIHI7UT+xBNPaPz48VqxYoUOHDigvLw8pw0AAFQdl8fIp0+frgceeEDXXnutJOmGG25welWrYRiyWCyy2WzejxIAAG8I0KraEy4n8mnTpumuu+7Sf/7zH1/GAwCAb5j9OXLDKLuDbt26+SwYAADgHrceP/u9Vc8AAAhkvBBGUrNmzS6YzI8fP+5RQAAA+ITZu9alsnHys9/sBgAA/MetRD548GDVrVvXV7EAAOAzpu9aZ3wcABDUQrRr3eUXwpTPWgcAAIHD5Yrcbrf7Mg4AAHwrRCtyt5cxBQAgGJl+jBwAgKAWohW524umAACAC9uwYYP69eunlJQUWSwWLVu2zOl7wzA0efJk1atXT9HR0erZs6d27drl9nVI5AAAc6ji9cgLCgrUrl07zZ0795zfz5gxQ3PmzNG8efP02WefqXr16urdu7cKCwvdug5d6wAAU6jqMfK+ffuqb9++5/zOMAzNnj1bjz32mPr37y9JWrhwoZKSkrRs2TINHjzY5etQkQMAUMX27NmjgwcPqmfPno62+Ph4dezYUVu2bHHrXFTkAABz8NJkt7y8PKdmq9Uqq9Xq1qkOHjwoSUpKSnJqT0pKcnznKipyAIAplHete7JJUmpqquLj4x1bRkaGX++LihwAADfs27dPcXFxjs/uVuOSlJycLEk6dOiQ6tWr52g/dOiQ2rdv79a5qMgBAObgpVnrcXFxTltlEnmjRo2UnJysNWvWONry8vL02WefqVOnTm6di4ocAGAOVfxCmPz8fOXk5Dg+79mzR1lZWUpMTFSDBg10//3364knntDFF1+sRo0aadKkSUpJSdGAAQPcug6JHAAAH9i6dat69Ojh+Dxu3DhJUnp6ujIzM/Xggw+qoKBAd955p06cOKGrrrpKK1euVFRUlFvXIZEDAEzB8uvmyfHu6N69+++uHGqxWDR9+nRNnz7dg6hI5AAAswjRd62TyAEAphCqq58xax0AgCBGRQ4AMAe61gEACHIBmow9Qdc6AABBjIocAGAKoTrZjUQOADCHEB0jp2sdAIAgRkUOADAFutYBAAhmdK0DAIBAQ0UOADAFutYBAAhmIdq1TiIHAJhDiCZyxsgBAAhiVOQAAFNgjBwAgGBG1zoAAAg0VOQAAFOwGIYsRuXLak+O9SUSOQDAHOhaBwAAgYaKHABgCsxaBwAgmNG1DgAAAg0VOQDAFOhaBwAgmIVo1zqJHABgCqFakTNGDgBAEKMiBwCYA13rAAAEt0DtHvcEXesAAAQxKnIAgDkYRtnmyfEBiEQOADAFZq0DAICAQ0UOADAHZq0DABC8LPayzZPjAxFd6wAABDEqcris37Cjuvnuw0qsU6rd30XrhccuUnZWjL/DAtxWmlWiosVnZMsulXHMUMxTsarWNdLxvf24XYUvnlbp58Uy8g1FtKumqLHVFZ4a7seo4bEQ7Vr3a0W+YcMG9evXTykpKbJYLFq2bJk/w8Hv6HbDL7pzyn4tmpms0b2bafd3UXpy8W7F1yrxd2iA24wzhsKbRih6XPWK3xmGTk88Jft+m2L+Fqca8xMUlhymgvvzZJwJ0H/J4ZLyWeuebIHIr4m8oKBA7dq109y5c/0ZBlww8M6jWrk4UR8vSdTeXVGa81B9FZ2xqPeQ4/4ODXBbtU6RirozRtW6WSt8Z99nl+3bUkU/UF0RLSMU3iBcUeOrS0WGSlYX+SFaeE35c+SebAHIr13rffv2Vd++ff0ZAlwQUc2ui9ue1hvP13W0GYZFX26MVasOp/0YGeADJb/+Y221OJosYRYp0qLS7aWK7OenuIDzCKrJbkVFRcrLy3Pa4HtxiTaFR0gnjjj/3ffL0QjVrFPqp6gA3whLC5clKUxF807LyLPLKDFU9M8zMg7bZRwL0GnLcAld6wEgIyND8fHxji01NdXfIQEIMZYIi6o/GSvbPpvyrv1FeT2Pq/SLEkX8oZpkufDxCGCGF7YAFFSJfOLEiTp58qRj27dvn79DMoW84+GylUoJZ1XfNWuX6pcjPPiA0BPeIkKxmQmKW1lTsctqqvrMOBknDYWlBNU/mTCJoPqttFqtiouLc9rge6UlYdq1PUaXXnXK0WaxGGp/Vb6+28bjZwhdlhphCqsZJts+m2zZpYroEnnhgxCwQrVrnXIKLnn35doaP3ufvv8qRtlfxujGUUcUFWPXx28k+js0wG3GaUP2n22Oz/YDNtl2lcoSa1FYcrhK1hbJkhCmsKQw2XbbdObZAkV0iVS1K0nkQY3Vz7wvPz9fOTk5js979uxRVlaWEhMT1aBBAz9GhrOtf7+m4mvZdPuEg6pZp1S7v43Wo0Mb6cTRav4ODXCbbWepCu7932TZwufKnr6o1teqmEdryH7MrqLnT8s4bpelVpgi+1hlHRbtr3CB3+XXRL5161b16NHD8XncuHGSpPT0dGVmZvopKpzP+/Nr6/35tf0dBuCxiMuqKX5TrfN+b/1TtKx/InGHmlBdxtSvibx79+4yArSrAgAQYnhFKwAACDRMdgMAmAJd6wAABDO7UbZ5cnwAIpEDAMyBMXIAABBoqMgBAKZgkYdj5F6LxLtI5AAAcwjRN7vRtQ4AQBCjIgcAmAKPnwEAEMyYtQ4AAFw1depUWSwWp61FixZevw4VOQDAFCyGIYsHE9Yqc+wll1yi1atXOz5HRHg/7ZLIAQDmYP918+R4N0VERCg5OdmDi14YXesAAPjIrl27lJKSosaNG2vo0KHau3ev169BRQ4AMAVvda3n5eU5tVutVlmt1gr7d+zYUZmZmWrevLkOHDigadOmqUuXLvrmm28UGxtb6TjORkUOADAHwwubpNTUVMXHxzu2jIyMc16ub9+++tOf/qS2bduqd+/e+vDDD3XixAm9+eabXr0tKnIAgDl46c1u+/btU1xcnKP5XNX4uSQkJKhZs2bKycmpfAznQEUOAIAb4uLinDZXE3l+fr5yc3NVr149r8ZDIgcAmEL5m9082dwxfvx4rV+/Xj/88IM2b96sG2+8UeHh4RoyZIhX74uudQCAOVTxoik//fSThgwZomPHjqlOnTq66qqr9Omnn6pOnTqVj+EcSOQAAPjAG2+8USXXIZEDAEzBYi/bPDk+EJHIAQDmwHrkAAAg0FCRAwDMIUSXMSWRAwBMwR+rn1UFutYBAAhiVOQAAHMI0cluJHIAgDkY8mw98sDM4yRyAIA5MEYOAAACDhU5AMAcDHk4Ru61SLyKRA4AMIcQnexG1zoAAEGMihwAYA52SRYPjw9AJHIAgCkwax0AAAQcKnIAgDmE6GQ3EjkAwBxCNJHTtQ4AQBCjIgcAmEOIVuQkcgCAOfD4GQAAwYvHzwAAQMChIgcAmANj5AAABDG7IVk8SMb2wEzkdK0DABDEqMgBAOZA1zoAAMHMw0SuwEzkdK0DABDEqMgBAOZA1zoAAEHMbsij7nFmrQMAAG+jIgcAmINhL9s8OT4AkcgBAObAGDkAAEGMMXIAABBoqMgBAOZA1zoAAEHMkIeJ3GuReBVd6wAABDEqcgCAOdC1DgBAELPbJXnwLLg9MJ8jp2sdAIAgRkUOADAHutYBAAhiIZrI6VoHACCIUZEDAMwhRF/RSiIHAJiCYdhleLCCmSfH+hKJHABgDobhWVXNGDkAAPA2KnIAgDkYHo6RB2hFTiIHAJiD3S5ZPBjnDtAxcrrWAQAIYlTkAABzoGsdAIDgZdjtMjzoWg/Ux8/oWgcAIIhRkQMAzIGudQAAgpjdkCyhl8jpWgcAIIhRkQMAzMEwJHnyHHlgVuQkcgCAKRh2Q4YHXetGgCZyutYBAOZg2D3fKmHu3Llq2LChoqKi1LFjR33++edevS0SOQAAPrJkyRKNGzdOU6ZM0RdffKF27dqpd+/eOnz4sNeuQSIHAJiCYTc83tw1c+ZMjRo1SsOHD1erVq00b948xcTE6LXXXvPafZHIAQDmUMVd68XFxdq2bZt69uzpaAsLC1PPnj21ZcsWr91WUE92K594UKoSj57xBwJZSUGxv0MAfKb897sqJpJ5mitKVSJJysvLc2q3Wq2yWq0V9j969KhsNpuSkpKc2pOSkrRz587KB3KWoE7kp06dkiRt0od+jgTwoV7+DgDwvVOnTik+Pt4n546MjFRycrI2HfQ8V9SoUUOpqalObVOmTNHUqVM9PndlBXUiT0lJ0b59+xQbGyuLxeLvcEwhLy9Pqamp2rdvn+Li4vwdDuBV/H5XPcMwdOrUKaWkpPjsGlFRUdqzZ4+Kiz3v3TIMo0K+OVc1Lkm1a9dWeHi4Dh065NR+6NAhJScnexxLuaBO5GFhYapfv76/wzCluLg4/qFDyOL3u2r5qhL/raioKEVFRfn8Or8VGRmpDh06aM2aNRowYIAkyW63a82aNRozZozXrhPUiRwAgEA2btw4paen6/LLL9eVV16p2bNnq6CgQMOHD/faNUjkAAD4yKBBg3TkyBFNnjxZBw8eVPv27bVy5coKE+A8QSKHW6xWq6ZMmXLeMSEgmPH7DV8YM2aMV7vSz2YxAvXlsQAA4IJ4IQwAAEGMRA4AQBAjkQMAEMRI5AAABDESOVzm6zV1AX/ZsGGD+vXrp5SUFFksFi1btszfIQEuI5HDJVWxpi7gLwUFBWrXrp3mzp3r71AAt/H4GVzSsWNHXXHFFXr++ecllb1mMDU1Vffcc48efvhhP0cHeI/FYtHSpUsdr9QEAh0VOS6oqtbUBQC4j0SOC/q9NXUPHjzop6gAABKJHACAoEYixwVV1Zq6AAD3kchxQb9dU7dc+Zq6nTp18mNkAABWP4NLqmJNXcBf8vPzlZOT4/i8Z88eZWVlKTExUQ0aNPBjZMCF8fgZXPb888/r6aefdqypO2fOHHXs2NHfYQEeW7dunXr06FGhPT09XZmZmVUfEOAGEjkAAEGMMXIAAIIYiRwAgCBGIgcAIIiRyAEACGIkcgAAghiJHACAIEYiBwAgiJHIAQ8NGzbMae3q7t276/7776/yONatWyeLxaITJ06cdx+LxaJly5a5fM6pU6eqffv2HsX1ww8/yGKxKCsry6PzADg3EjlC0rBhw2SxWGSxWBQZGammTZtq+vTpKi0t9fm13333XT3++OMu7etK8gWA38O71hGy+vTpo/nz56uoqEgffvihRo8erWrVqmnixIkV9i0uLlZkZKRXrpuYmOiV8wCAK6jIEbKsVquSk5OVlpamu+++Wz179tT7778v6X/d4U8++aRSUlLUvHlzSdK+fft0yy23KCEhQYmJierfv79++OEHxzltNpvGjRunhIQE1apVSw8++KDOfsvx2V3rRUVFeuihh5Samiqr1aqmTZvq1Vdf1Q8//OB4v3fNmjVlsVg0bNgwSWWry2VkZKhRo0aKjo5Wu3bt9Pbbbztd58MPP1SzZs0UHR2tHj16OMXpqoceekjNmjVTTEyMGjdurEmTJqmkpKTCfi+99JJSU1MVExOjW265RSdPnnT6/pVXXlHLli0VFRWlFi1a6IUXXnA7FgCVQyKHaURHR6u4uNjxec2aNcrOztaqVau0YsUKlZSUqHfv3oqNjdXGjRv1ySefqEaNGurTp4/juGeeeUaZmZl67bXXtGnTJh0/flxLly793evefvvt+te//qU5c+Zox44deumll1SjRg2lpqbqnXfekSRlZ2frwIEDevbZZyVJGRkZWrhwoebNm6dvv/1WY8eO1W233ab169dLKvuDY+DAgerXr5+ysrI0cuRIPfzww27/TGJjY5WZmanvvvtOzz77rP7xj39o1qxZTvvk5OTozTff1PLly7Vy5Up9+eWX+utf/+r4ftGiRZo8ebKefPJJ7dixQ0899ZQmTZqkBQsWuB0PgEowgBCUnp5u9O/f3zAMw7Db7caqVasMq9VqjB8/3vF9UlKSUVRU5Djm9ddfN5o3b27Y7XZHW1FRkREdHW189NFHhmEYRr169YwZM2Y4vi8pKTHq16/vuJZhGEa3bt2M++67zzAMw8jOzjYkGatWrTpnnP/5z38MScYvv/ziaCssLDRiYmKMzZs3O+07YsQIY8iQIYZhGMbEiRONVq1aOX3/0EMPVTjX2SQZS5cuPe/3Tz/9tNGhQwfH5ylTphjh4eHGTz/95Gj797//bYSFhRkHDhwwDMMwmjRpYixevNjpPI8//rjRqVMnwzAMY8+ePYYk48svvzzvdQFUHmPkCFkrVqxQjRo1VFJSIrvdrltvvVVTp051fN+mTRuncfGvvvpKOTk5io2NdTpPYWGhcnNzdfLkSR04cMBp6daIiAhdfvnlFbrXy2VlZSk8PFzdunVzOe6cnBydPn1a11xzjVN7cXGxLr30UknSjh07Kiwh26lTJ5evUW7JkiWaM2eOcnNzlZ+fr9LSUsXFxTnt06BBA1100UVO17Hb7crOzlZsbKxyc3M1YsQIjRo1yrFPaWmp4uPj3Y4HgPtI5AhZPXr00IsvvqjIyEilpKQoIsL517169epOn/Pz89WhQwctWrSowrnq1KlTqRiio6PdPiY/P1+S9MEHHzglUKls3N9btmzZoqFDh2ratGnq3bu34uPj9cYbb+iZZ55xO9Z//OMfFf6wCA8P91qsAM6PRI6QVb16dTVt2tTl/S+77DItWbJEdevWrVCVlqtXr54+++wzde3aVVJZ5blt2zZddtll59y/TZs2stvtWr9+vXr27Fnh+/IeAZvN5mhr1aqVrFar9u7de95KvmXLlo6Je+U+/fTTC9/kb2zevFlpaWl69NFHHW0//vhjhf327t2r/fv3KyUlxXGdsLAwNW/eXElJSUpJSdHu3bs1dOhQt64PwDuY7Ab8aujQoapdu7b69++vjRs3as+ePVq3bp3uvfde/fTTT5Kk++67T3/729+0bNky7dy5U3/9619/9xnwhg0bKj09XXfccYeWLVvmOOebb74pSUpLS5PFYtGKFSt05MgR5efnKzY2VuPHj9fYsWO1YMEC5ebm6osvvtBzzz3nmEB21113adeuXZowYYKys7O1ePFiZWZmunW/F198sfbu3as33nhDubm5mjNnzjkn7kVFRSk9PV1fffWVNm7cqHvvvVe33HKLkpOTJUnTpk1TRkaG5syZo++//15ff/215s+fr5kzZ7oVD4DKIZEDv4qJidGGDRvUoEEDDRw4UC1bttSIESNUWFjoqNAfeOAB/fnPf1Z6ero6deqk2NhY3Xjjjb973hdffFE333yz/vrXv6pFixYaNWqUCgoKJEkXXXSRpk2bpocfflhJSUkaM2aMJOnxxx/XpEmTlJGRoZYtW6pPnz764IMP1KhRI0ll49bvvPOOli1bpnbt2mnevHl66qmn3LrfG264QWPHjtWYMWPUvn17bd68WZMmTaqwX9OmTTVw4EBde+216tWrl9q2bev0eNnIkSP1yiuvaP78+WrTpo26deumzMxMR6wAfMtinG+WDgAACHhU5AAABDESOQAAQYxEDgBAECORAwAQxEjkAAAEMRI5AABBjEQOAEAQI5EDABDESOQAAAQxEjkAAEGMRA4AQBAjkQMAEMT+P4naUzeK1ICrAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**13. Handling Imbalanced Data with Class Weights**"
      ],
      "metadata": {
        "id": "VQm8ZNDTkvyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = (data.target == 0).astype(int)  # Binary classification\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Logistic Regression with class weights\n",
        "model = LogisticRegression(class_weight='balanced')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy with Class Weights: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3H3NbLxkmLZ",
        "outputId": "78c4f125-fabf-4f4e-fd0c-c6bdd4fd40b6"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with Class Weights: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**14. Logistic Regression on Titanic Dataset**"
      ],
      "metadata": {
        "id": "83l8HYrPk5WO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load Titanic dataset\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv')\n",
        "\n",
        "# Preprocessing\n",
        "df = df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Survived']]\n",
        "df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "df[['Age']] = imputer.fit_transform(df[['Age']])\n",
        "\n",
        "# Split into features and target\n",
        "X = df.drop('Survived', axis=1)\n",
        "y = df['Survived']\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Logistic Regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy on Titanic Dataset: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BtPpKSvkypD",
        "outputId": "9ececdb9-f22e-4c32-9c60-d08685b54ce1"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy on Titanic Dataset: 0.81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**15. Feature Scaling with Standardization**"
      ],
      "metadata": {
        "id": "arWPOOvflAgd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = (data.target == 0).astype(int)  # Binary classification\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train Logistic Regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy with Feature Scaling: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7n82Pj_Ek85y",
        "outputId": "bdb6c744-b196-4aa9-800e-bce74099dd6c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with Feature Scaling: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**16. ROC-AUC Score Evaluation**"
      ],
      "metadata": {
        "id": "D1kSFGRwlE6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = (data.target == 0).astype(int)  # Binary classification\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Logistic Regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities and evaluate\n",
        "y_probs = model.predict_proba(X_test)[:, 1]\n",
        "roc_auc = roc_auc_score(y_test, y_probs)\n",
        "print(f\"ROC-AUC Score: {roc_auc:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-krknjzXlCkm",
        "outputId": "c3066252-843f-4b70-9f6e-07d426e692d2"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**17. Custom Learning Rate (C=0.5)**"
      ],
      "metadata": {
        "id": "h-dy2UJtlI8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = (data.target == 0).astype(int)  # Binary classification\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Logistic Regression with custom C\n",
        "model = LogisticRegression(C=0.5)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy with C=0.5: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJQwZxwClHBo",
        "outputId": "7b6b129b-ae55-402b-a608-2c983d566500"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with C=0.5: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**18. Feature Importance from Coefficients**"
      ],
      "metadata": {
        "id": "sNXCZwdVlM-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = (data.target == 0).astype(int)  # Binary classification\n",
        "\n",
        "# Train Logistic Regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Feature importance\n",
        "importance = pd.DataFrame({'Feature': data.feature_names, 'Coefficient': model.coef_[0]})\n",
        "print(importance.sort_values(by='Coefficient', ascending=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rByLjff2lK_W",
        "outputId": "62317401-cd1f-4d99-c0c3-ebade29bb291"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             Feature  Coefficient\n",
            "1   sepal width (cm)     0.900546\n",
            "0  sepal length (cm)    -0.445651\n",
            "3   petal width (cm)    -0.981129\n",
            "2  petal length (cm)    -2.320233\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**19. Cohen's Kappa Score Evaluation**"
      ],
      "metadata": {
        "id": "D_7CIPixlSVD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = (data.target == 0).astype(int)  # Binary classification\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Logistic Regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "kappa = cohen_kappa_score(y_test, y_pred)\n",
        "print(f\"Cohen's Kappa Score: {kappa:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SdNu8QblPbP",
        "outputId": "c6593212-6da6-4ca9-bf21-e80eb8e6853b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cohen's Kappa Score: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**20. Precision-Recall Curve**"
      ],
      "metadata": {
        "id": "jhy7jLamlajD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = (data.target == 0).astype(int)  # Binary classification\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Logistic Regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities\n",
        "y_probs = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Precision-Recall Curve\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_probs)\n",
        "plt.plot(recall, precision, marker='.')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "1x6Pa5NqlXX7",
        "outputId": "bc7789d4-effd-4773-8647-ac58ba032701"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**21. Compare Solvers (liblinear, saga, lbfgs)**"
      ],
      "metadata": {
        "id": "FIPfo9fxlhfb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = (data.target == 0).astype(int)  # Binary classification\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Compare solvers\n",
        "solvers = ['liblinear', 'saga', 'lbfgs']\n",
        "for solver in solvers:\n",
        "    model = LogisticRegression(solver=solver)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Accuracy with {solver}: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SI33wk-UldVI",
        "outputId": "2cdc9b08-616c-45fa-ee04-29b3fb84baec"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with liblinear: 1.00\n",
            "Accuracy with saga: 1.00\n",
            "Accuracy with lbfgs: 1.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**22. Matthews Correlation Coefficient (MCC)**"
      ],
      "metadata": {
        "id": "JhdSDuAclmW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = (data.target == 0).astype(int)  # Binary classification\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Logistic Regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "print(f\"Matthews Correlation Coefficient: {mcc:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cy6H_2DSljx5",
        "outputId": "490d0cd8-0905-4af8-83bd-cba3ec841236"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matthews Correlation Coefficient: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**23. Compare Raw vs Standardized Data**"
      ],
      "metadata": {
        "id": "js6ckMpFlpfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = (data.target == 0).astype(int)  # Binary classification\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train on raw data\n",
        "model_raw = LogisticRegression()\n",
        "model_raw.fit(X_train, y_train)\n",
        "y_pred_raw = model_raw.predict(X_test)\n",
        "accuracy_raw = accuracy_score(y_test, y_pred_raw)\n",
        "\n",
        "# Standardize data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train on standardized data\n",
        "model_scaled = LogisticRegression()\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "print(f\"Accuracy (Raw Data): {accuracy_raw:.2f}, Accuracy (Standardized Data): {accuracy_scaled:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hn1J89zYlorA",
        "outputId": "a4337890-ccdd-4680-fd25-7b430fbd1752"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (Raw Data): 1.00, Accuracy (Standardized Data): 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**24. Optimal C (Regularization Strength) with Cross-Validation**"
      ],
      "metadata": {
        "id": "qkj4LhlHlxja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = (data.target == 0).astype(int)  # Binary classification\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Find optimal C with cross-validation\n",
        "model = LogisticRegressionCV(Cs=[0.01, 0.1, 1, 10], cv=5)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Optimal C: {model.C_}, Model Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMMJbs1mlt9_",
        "outputId": "a81a1350-333d-4133-c4f8-e40a878b2491"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal C: [0.1], Model Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**25. Save and Load Model with Joblib**"
      ],
      "metadata": {
        "id": "REqWs6XEl3Pc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import joblib\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = (data.target == 0).astype(int)  # Binary classification\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Logistic Regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Save model\n",
        "joblib.dump(model, 'logistic_regression_model.pkl')\n",
        "\n",
        "# Load model\n",
        "loaded_model = joblib.load('logistic_regression_model.pkl')\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = loaded_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkW6brDzl0sP",
        "outputId": "6074b62c-ae2d-48b7-8b66-64abca3a826f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 1.00\n"
          ]
        }
      ]
    }
  ]
}